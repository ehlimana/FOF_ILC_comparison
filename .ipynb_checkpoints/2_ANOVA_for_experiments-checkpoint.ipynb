{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook has been developed for the purposes of the EMPIR project “Metrology for the Factory of the Future” (Met4FoF) -  Activity A1.2.2 of the Work Package 1.Two laboratories in PTB and CEM posses conventional dynamic calibration set-ups for acceleration sensors under test. The objective was to extend current calibration systems for digital-output sensors.  The objective of the task is to compare measurement results of the two laboratories, PTB and CEM, provided by the extended dynamic calibration systems. \n",
    "\n",
    "## 1.1. State of the art\n",
    "\n",
    "In conventional dynamic calibration procedures for acceleration sensors, the acceleration used for the sensor input is applied either as **a sinusoidal excitation with a given frequency and amplitude** or as **a singular shock-like excitation characterized by pulse width and intensity**. \n",
    "<br>The quantity is then measured by a reference sensor and by the device under test (DUT). The results of DUT are compared to the reference and hence characterized and linked to the SI. In a dynamic calibration situation, the response of the DUT to time-varying input is the major interest. Hence, it is crucial that the mechanical input operates simultaneously and equally on the reference and DUT. Both, the reference and the DUT provide **electrical outputs (typical voltage)** while **the data acquisition electronics** of the system provides **the analogue to digital conversion (ADC).**\n",
    "In order to connect the reference and the DUT to the ADC system, two analogue channels are needed. In order to get reliable information on the time dependent response, the timing of the data acquisition on the two channels has to be synchronized. This is typically accomplished by provision of a common clock signal to drive the sampling units of the ADC and a common trigger to start (or mark) the beginning of the acquisition. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. The extension of conventional dynamic calibration systems to digital-output sensors \n",
    "\n",
    "In a set-up where the DUT is a digital-output sensor,the sampling of the DUT time series is no longer under the control (trigger, clock) of the calibration system. Instead, the DUT comprises its own digitizer unit with a time base independent of the calibration system. In fact, a typical conventional calibration set-up does not provide an input for digital data at all.\n",
    "The solution to this problem requires two extensions:\n",
    "1.\tA digital acquisition unit (DAU) which is capable to connect to the digital interface of the sensor under calibration and store/transmit the DUT time-series for later analysis\n",
    "2.\tAn additional synchronization signal that provides the link between the time-base of the calibration system and the time-base of the DUT.\n",
    "\n",
    "The concept for the extension of existing facilities for dynamic calibration uses a custom digital acquisition unit microcontroller board with a connected reference time signal for traceable time stamping of acquired data points. This allows for a synchronised data acquisition from the reference measurement and the DUT. The selected sensor for acceleration measurements is a three axial low-g acceleration sensor with digital output, which allows measurements of acceleration in three perpendicular axes.**At the moment and in this notebook, only an X-axis acceleration has been observed.** \n",
    "    \n",
    "The selected laboratories posses their set-ups and the calibration items were calibrated in both set-ups.The analysis required transformation from time domain to the frequency domain, where frequencies and corresponding magnitudes and phases were calculated.The measurement conditions were kept according to the laboratory standard conditions. \n",
    "\n",
    "Each laboratory submitted HDFT files containing groups:\n",
    "- EXPERIMENTS - containing 171 files (experiment) corresponding to the sine excitations\n",
    "- RAWDATA - where data from ADCs (*voltage, absolute time, absolute time uncertainty*)  and sensors (*absolute time, absolute time uncertainty, acceleration, angular velocity, magnetic flux density and temperature*) can be approached during the measurements\n",
    "- RAWTRANSFERFUNCTION - *this group contains quantities of interest: frequencies, amplitudes, assigned uncertainties of amplitudes, phases,  assigned uncertainties of phases, excitation amplitudes and assigned uncertainties of excitation amplitudes\n",
    "- REFERENCEDATA - reference data from ADCs and sensors.\n",
    "\n",
    "    \n",
    "| <b>PTB<b> | Sensor | Internal ADC |\n",
    "| --- | --- | --- |\n",
    "| <b>Name<b> | MPU 9250| STM 32 Internal ADC |\n",
    "| <b>ID<b>  | 535035904 | 535038464 |\n",
    "| <b>Quantity<b>  | X Acceleration | Voltage  @CH1 |\n",
    "| <b>Unit<b>  | $\\frac{m}{s^{2}}$ | V |    \n",
    "| <b>Resolution<b>  | 65536,0 (16-bit) | 4096,0 (12-bit) |\n",
    "| <b>Min. scale<b>  | -156,91439819335938 $\\frac{m}{s^{2}}$  | -10 V |\n",
    "| <b>Min. scale<b>  | 156,90960693359375 $\\frac{m}{s^{2}}$  | 10 V |\n",
    "    \n",
    "| <b>CEM<b> | Sensor | Internal ADC |\n",
    "| --- | --- | --- |\n",
    "| <b>Name<b> | MPU 9250| STM 32 Internal ADC |\n",
    "| <b>ID<b>  | 3167420416 | 31674422976 |\n",
    "| <b>Quantity<b>  | X Acceleration | Voltage  @CH1 |\n",
    "| <b>Unit<b>  | $\\frac{m}{s^{2}}$ | V |    \n",
    "| <b>Resolution<b>  | 65536,0 (16-bit) | 4096,0 (12-bit) |\n",
    "| <b>Min. scale<b>  | -156,91439819335938 $\\frac{m}{s^{2}}$  | -10 V |\n",
    "| <b>Min. scale<b>  | 156,90960693359375 $\\frac{m}{s^{2}}$  | 10 V |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import openpyxl\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.Extract the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data for ILC comparison is extracted from the HDF5 files separately for PTB and CEM. The extracted data will be sorted by frequency at the end of the Notebook and saved into Excel file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(filename, sensor_index):\n",
    "    #explore the HDF5 file, folders and subfolders\n",
    "    with h5py.File(filename,'r') as f:\n",
    "        base_items=list(f.items())\n",
    "        print(\"\\nItems in directory\", base_items)\n",
    "        rawtransfer=f.get(\"RAWTRANSFERFUNCTION\")\n",
    "        rawtransfer_items=list(rawtransfer.items())\n",
    "        print(\"\\nItems in reference\", rawtransfer_items)\n",
    "        subgroup=rawtransfer.get(\"/RAWTRANSFERFUNCTION/\"+sensor_index+\"_MPU_9250\")\n",
    "        subgroup_items=list(subgroup.items())\n",
    "        print(\"\\n\"+sensor_index+\"_MPU_9250 items:\",subgroup_items)\n",
    "        subgroup_acceleration=subgroup.get(\"/RAWTRANSFERFUNCTION/\"+sensor_index+\"_MPU_9250/Acceleration\")\n",
    "        subgroup_acceleration_items=list(subgroup_acceleration.items())\n",
    "        print(\"\\nAcceleration items:\",subgroup_acceleration_items)\n",
    "        subgroup_acceleration_5mem=subgroup.get(\"/RAWTRANSFERFUNCTION/\"+sensor_index+\"_MPU_9250/Acceleration/Acceleration\")\n",
    "        subgroup_acceleration_5mem_items=list(subgroup_acceleration_5mem.items())\n",
    "        print(\"\\nAcceleration items_5members:\", subgroup_acceleration_5mem_items)\n",
    "        frequency=subgroup_acceleration_5mem.get(\"/RAWTRANSFERFUNCTION/\"+sensor_index+\"_MPU_9250/Acceleration/Acceleration/Frequency\")\n",
    "        frequency_items=list(frequency.items())\n",
    "        print(\"\\nFrequency\", frequency_items)\n",
    "        magnitude=subgroup_acceleration_5mem.get(\"/RAWTRANSFERFUNCTION/\"+sensor_index+\"_MPU_9250/Acceleration/Acceleration/Magnitude\")\n",
    "        magnitude_items=list(magnitude.items())\n",
    "        print(\"\\nMagnitude\", magnitude_items)\n",
    "        phase=subgroup_acceleration_5mem.get(\"/RAWTRANSFERFUNCTION/\"+sensor_index+\"_MPU_9250/Acceleration/Acceleration/Phase\")\n",
    "        phase_items=list(magnitude.items())\n",
    "        print(\"\\nPhase\", phase_items)\n",
    "        \n",
    "        \n",
    "        #extract frequencies, magnitude, phase, uncertainties and all excitation parameters\n",
    "        frequency_values=np.array(frequency.get(\"value\"))\n",
    "        magnitude_values=np.array(magnitude.get(\"value\"))\n",
    "        magnitude_uncertainties=np.array(magnitude.get(\"uncertainty\"))\n",
    "        phase_values=np.array(phase.get(\"value\"))\n",
    "        phase_uncertainties=np.array(phase.get(\"uncertainty\"))\n",
    "        excitation_freq_items=subgroup_acceleration_5mem.get(\"/RAWTRANSFERFUNCTION/\"+sensor_index+\"_MPU_9250/Acceleration/Acceleration/Excitation_frequency\")\n",
    "        excitation_freq=np.array(excitation_freq_items.get(\"value\"))\n",
    "        excitation_amp_items=subgroup_acceleration_5mem.get(\"/RAWTRANSFERFUNCTION/\"+sensor_index+\"_MPU_9250/Acceleration/Acceleration/Excitation_amplitude\")\n",
    "        excitation_amp=np.array(excitation_amp_items.get(\"value\"))\n",
    "        excitation_amp_uncertainty=np.array(excitation_amp_items.get(\"uncertainty\"))\n",
    "        \n",
    "        #join all necessary data in 2D array\n",
    "        total_array=np.stack((frequency_values,magnitude_values,magnitude_uncertainties,phase_values, phase_uncertainties,excitation_freq,excitation_amp,excitation_amp_uncertainty), axis=1)\n",
    "        print(\"\\nArray dimensions:\", total_array.shape)\n",
    "        column_names=[\"Frequency [Hz]\", r\"$x_{M},$ [m s^-2/m s^-2]\",r\"$U_{M},$ [m s^-2/m s^-2]\", r\"$x_{\\phi},$ [°]\", r\"$U_{\\phi},$ [°]\",\"Excitation_freq [Hz]\",r\"$x_{Aexcit},$ [m s^-2/m s^-2]\",r\"$U_{Aexcit},$ [m s^-2/m s^-2]\"]\n",
    "        whole_dataset=pd.DataFrame(total_array, columns=column_names)\n",
    "        f.close()\n",
    "        \n",
    "        \n",
    "        return whole_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_dataset_PTB = extract_data('MPU9250PTB_v2.hdf5',\"0x1fe40000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_dataset_PTB.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Phase data for PTB must be reverted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_dataset_PTB[[r\"$x_{\\phi},$ [°]\"]] = whole_dataset_PTB[[r\"$x_{\\phi},$ [°]\"]]-np.pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_dataset_PTB.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_dataset_CEM = extract_data('MPU9250CEM_v2.hdf5',\"0xbccb0000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_dataset_CEM.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cycles in CEM's dataset start with 80.0 Hz and 250.0 Hz instead of 10.0 Hz. These starting points are deleted in order to compare the cycles in a range from 10.0 Hz and 250.Hz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_rows=[]\n",
    "\n",
    "for k in range(0,171,19):\n",
    "    i=k\n",
    "    j=k+1\n",
    "    delete_rows.append(i)\n",
    "    delete_rows.append(j)\n",
    "whole_dataset_CEM_new=whole_dataset_CEM.drop(axis=0,index=delete_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.Data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data_by_frequencies(dataset):\n",
    "    dict_of_frequencies=dict(iter(dataset.groupby('Frequency [Hz]')))\n",
    "    return dict_of_frequencies\n",
    "    #list_of_frequencies=np.array([10,12.5,16,20,25,31.5,40,46.7,50,53.3,63,80,100,125,160,200,250])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check if all frequencies are the same\n",
    "PTB_separated_by_freq=split_data_by_frequencies(whole_dataset_PTB)\n",
    "CEM_separated_by_freq=split_data_by_frequencies(whole_dataset_CEM)\n",
    "CEM_separated_by_freq_new=split_data_by_frequencies(whole_dataset_CEM_new)\n",
    "print(\"Frequencies - PTB:\",PTB_separated_by_freq.keys())\n",
    "print(\"Frequencies - CEM:\",CEM_separated_by_freq.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PTB_separated_by_freq.get(10).head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CEM_separated_by_freq.get(10).head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_names=list(PTB_separated_by_freq.get(10).columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. ANOVA for experiments performed at a given frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are three primary assumptions in ANOVA:\n",
    "\n",
    "<br>*The responses for each factor level have a normal population distribution.*\n",
    "<br>*These distributions have the same variance.*\n",
    "<br>*The data are independent.*\n",
    "<br>Violations to the first two that are not extreme can be considered not serious. The sampling distribution of the test statistic is fairly robust, especially as sample size increases and more so if the sample sizes for all factor levels are equal. If you conduct an ANOVA test, you should always try to keep the same sample sizes for each factor level.\n",
    "\n",
    "If our samples have unequal variances (heteroscedasticity), on the other hand, it can affect the Type I error rate and lead to false positives. This is, basically, what equality of variances means.\n",
    "\n",
    "<b>A general rule of thumb for equal variances is to compare the smallest and largest sample standard deviations. This is much like the rule of thumb for equal variances for the test for independent means. If the ratio of these two sample standard deviations falls within 0.5 to 2, then it may be that the assumption is not violated.<b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Tests for equality of variances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def rule_of_thumb_ANOVA(dictionary, index):  \n",
    "    ratio_amp=np.empty((len(dictionary.values())))\n",
    "    ratio_ph=np.empty((len(dictionary.values())))\n",
    "    ratio_ex=np.empty((len(dictionary.values())))\n",
    "    for val,f in zip (dictionary.values(),range(len(dictionary.values()))):\n",
    "            min_amp=min(val[r\"$U_{M},$ [m s^-2/m s^-2]\"].values/2)\n",
    "            max_amp=max(val[r\"$U_{M},$ [m s^-2/m s^-2]\"].values/2)\n",
    "            ratio_amp[f]=max_amp/min_amp\n",
    "\n",
    "            min_ph=min(val[r\"$U_{\\phi},$ [°]\"].values/2)\n",
    "            max_ph=max(val[r\"$U_{\\phi},$ [°]\"].values/2)\n",
    "            ratio_ph[f]=max_ph/min_ph\n",
    "\n",
    "            min_ex=min(val[r\"$U_{Aexcit},$ [m s^-2/m s^-2]\"].values/2)\n",
    "            max_ex=max(val[r\"$U_{Aexcit},$ [m s^-2/m s^-2]\"].values/2)\n",
    "            ratio_ex[f]=max_ex/min_ex\n",
    "    \n",
    "    ratios = {'Amplitude' : pd.Series(ratio_amp,index =index),\n",
    "              'Phase' : pd.Series(ratio_ph,index =index),\n",
    "              'Excitation amplitude' : pd.Series(ratio_ex,index =index),     \n",
    "             }\n",
    "    ratios=pd.DataFrame(ratios, index=index)  \n",
    "    return ratios.style.applymap(lambda x: 'background-color : red' if x>2 else 'background-color : green')\n",
    " #red - variances are not equal\n",
    "# green - variances are equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_freq=[10,12.5,16,20,25,31.5,40,46.7,50,53.3,63,80,100,125,160,200,250]\n",
    "rule_of_thumb_ANOVA(PTB_separated_by_freq,list_of_freq)\n",
    "\n",
    "#63-125 the system is thumbling and unstable - mechanical problems at freq higher than 63"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, another test for equality of variances has been performed. Bartlett’s test of homogeneity of variances is a test, that measures whether the variances are equal for all samples. If your data is normally distributed you can use Bartlett’s test instead of Levene’s.\n",
    "Whether conducting Levene’s Test or Bartlett’s Test of homogeneity of variance we are dealing with two hypotheses. These two are simply put:\n",
    "\n",
    "Null Hypothesis: the variances are equal across all samples/groups\n",
    "Alternative Hypothesis:  the variances are not equal across all samples/groups [5]\n",
    "<br> If the p-value is higher that 0.05, the null hypothesis cannot be rejected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def Bartlett_test(dictionary,index,lab):\n",
    "\n",
    "    barlet_amp=np.empty((len(dictionary.values())))\n",
    "    barlet_ph=np.empty((len(dictionary.values())))\n",
    "    barlet_ex=np.empty((len(dictionary.values())))\n",
    "    for val,f in zip (dictionary.values(),range(len(dictionary.values()))):\n",
    "        group=[None]*val.shape[0]\n",
    "        for item in range(val.shape[0]):\n",
    "            random1=np.random.normal(val[\"Magnitude [m s^-2/m s^-2 ]\"].values[item], val[\"Uncertainty [m s^-2/m s^-2 ]\"].values[item], 100)\n",
    "            #group[item]=random1\n",
    "        if lab==\"PTB\": \n",
    "            #bartlet_test = stats.bartlett(group[0],group[1],group[2],group[3],group[4],group[5],group[6],group[7],group[8],group[9])\n",
    "        elif lab==\"CEM\":\n",
    "            bartlet_test =stats.bartlett (group[0],group[1],group[2],group[3],group[4],group[5],group[6],group[7],group[8])\n",
    "        barlet_amp[f]=bartlet_test[1]\n",
    "       \n",
    "     \n",
    "    \n",
    "    for val,f in zip (dictionary.values(),range(len(dictionary.values()))):\n",
    "        for item in range(val.shape[0]):\n",
    "            random1=np.random.normal(val[\"Phase [°]\"].values[item], val[\"Uncertainty[°]\"].values[item], 100)\n",
    "            group[item]=random1\n",
    "        if lab==\"PTB\": \n",
    "            bartlet_test = stats.bartlett(group[0],group[1],group[2],group[3],group[4],group[5],group[6],group[7],group[8],group[9])\n",
    "        elif lab==\"CEM\":\n",
    "            bartlet_test =stats.bartlett (group[0],group[1],group[2],group[3],group[4],group[5],group[6],group[7],group[8])\n",
    "        barlet_ph[f]=bartlet_test[1]\n",
    "     \n",
    "                                                                      \n",
    "    for val,f in zip (dictionary.values(),range(len(dictionary.values()))):\n",
    "        for item in range(val.shape[0]):\n",
    "            random1=np.random.normal(val[\"Excitation_amplitude [m s^-2]\"].values[item], val[\"Excitation_amplitude_uncert [m s^-2]\"].values[item], 100)\n",
    "            group[item]=random1\n",
    "        if lab==\"PTB\": \n",
    "            bartlet_test = stats.bartlett(group[0],group[1],group[2],group[3],group[4],group[5],group[6],group[7],group[8],group[9])\n",
    "        elif lab==\"CEM\":\n",
    "            bartlet_test =stats.bartlett (group[0],group[1],group[2],group[3],group[4],group[5],group[6],group[7],group[8])\n",
    "        barlet_ex[f]=bartlet_test[1]\n",
    "        \n",
    "    barletts = {'Amplitude' : pd.Series(barlet_amp,index =index),\n",
    "              'Phase' : pd.Series(barlet_ph,index =index),\n",
    "              'Excitation amplitude' : pd.Series(barlet_ex,index =index),     \n",
    "             }\n",
    "    barletts=pd.DataFrame(barletts, index=index)    \n",
    "    return barletts.style.applymap(lambda x: 'background-color : red' if x<0.05 else 'background-color : green')\n",
    " #red - variances are not equal\n",
    "# green - variances are equal\n",
    "# the sampling from normal distributiion is questionable because of timeseries               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bartlett_test(PTB_separated_by_freq,list_of_freq,\"PTB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A one-way ANOVA uses the following null and alternative hypotheses:\n",
    "\n",
    "<br>H0 (a null hypothesis): μ1 = μ2 = μ3 = … = μk (all the population means are equal)\n",
    "<br>H1 (a research hypothesis): at least one population mean is different from the rest.\n",
    "<br> If the p-value is higher that 0.05, the null hypothesis cannot be rejected. [4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ANOVA_through_experiments(dictionary,index,lab):\n",
    " \n",
    "    p=np.empty((len(dictionary.values())))\n",
    "\n",
    "    for val,f in zip (dictionary.values(),range(len(dictionary.values()))):\n",
    "        group=[None]*val.shape[0]\n",
    "        for item in range(val.shape[0]):\n",
    "            random1=np.random.normal(val[r\"$x_{M},$ [m s^-2/m s^-2]\"].values[item], val[r\"$U_{M},$ [m s^-2/m s^-2]\"].values[item]/2, 100)\n",
    "            group[item]=random1\n",
    "            \n",
    "        if lab==\"PTB\": \n",
    "            F_statistic, pVal = stats.f_oneway(group[0],group[1],group[2],group[3],group[4],group[5],group[6],group[7],group[8],group[9]) \n",
    "        elif lab==\"CEM\":\n",
    "            F_statistic, pVal = stats.f_oneway(group[0],group[1],group[2],group[3],group[4],group[5],group[6],group[7],group[8])\n",
    "        p[f]=pVal\n",
    "     \n",
    "    df=pd.DataFrame(p,columns=[\"p-value (Magnitude) \"], index=index) \n",
    "\n",
    "          \n",
    "    for val,f in zip (dictionary.values(),range(len(dictionary.values()))):\n",
    "        group=[None]*val.shape[0]\n",
    "        for item in range(val.shape[0]):\n",
    "            random1=np.random.normal(val[r\"$x_{\\phi},$ [°]\"].values[item], val[r\"$U_{\\phi},$ [°]\"].values[item]/2, 100)\n",
    "            group[item]=random1\n",
    "        if lab==\"PTB\": \n",
    "            F_statistic, pVal = stats.f_oneway(group[0],group[1],group[2],group[3],group[4],group[5],group[6],group[7],group[8],group[9])\n",
    "            p[f]=pVal\n",
    "        elif lab==\"CEM\":\n",
    "            F_statistic, pVal = stats.f_oneway(group[0],group[1],group[2],group[3],group[4],group[5],group[6],group[7],group[8])\n",
    "        p[f]=pVal\n",
    "  \n",
    "    df[\"p-value (Phase) \"]=p    \n",
    "               \n",
    "    for val,f in zip (dictionary.values(),range(len(PTB_separated_by_freq.values()))):\n",
    "        group=[None]*val.shape[0]\n",
    "        for item in range(val.shape[0]):\n",
    "            random1=np.random.normal(val[r\"$x_{Aexcit},$ [m s^-2/m s^-2]\"].values[item], val[r\"$U_{Aexcit},$ [m s^-2/m s^-2]\"].values[item]/2, 100)\n",
    "            group[item]=random1\n",
    "        if lab==\"PTB\": \n",
    "            F_statistic, pVal = stats.f_oneway(group[0],group[1],group[2],group[3],group[4],group[5],group[6],group[7],group[8],group[9])\n",
    "            p[f]=pVal\n",
    "        elif lab==\"CEM\":\n",
    "            F_statistic, pVal = stats.f_oneway(group[0],group[1],group[2],group[3],group[4],group[5],group[6],group[7],group[8]) \n",
    "        p[f]=pVal      \n",
    "        \n",
    "    df[\"p-value (Excitatiom amplitude) \"]=p  \n",
    "    return df.style.applymap(lambda x: 'background-color : yellow' if x<0.05 else 'background-color : green')\n",
    "\n",
    " #yellow - the null hypothesis can be rejected. \n",
    "# green - the null hypothesis cannot be rejected. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANOVA_through_experiments(PTB_separated_by_freq,list_of_freq,\"PTB\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANOVA_through_experiments(CEM_separated_by_freq_new,list_of_freq,\"CEM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] https://www.investopedia.com/terms/c/coefficientofvariation.asp\n",
    "<br>[2] https://en.wikipedia.org/wiki/Weighted_arithmetic_mean\n",
    "<br>[3] https://en.wikipedia.org/wiki/Effective_sample_size\n",
    "<br>[4] https://online.stat.psu.edu/stat500/lesson/10/10.2/10.2.1\n",
    "<br>[5] https://www.marsja.se/levenes-bartletts-test-of-equality-homogeneity-of-variance-in-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
